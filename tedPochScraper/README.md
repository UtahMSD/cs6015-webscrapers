This scraper is pretty basic. The point was to dabble a tad in web scraping
using some of the more modern libraries available for Python.

There is not yet error checking where there should be. I would also like to
parse NOAA's webpage for the relevant locations first, before then offering
those as choices. As it stands, this script just calls SLC and the more
interesting towns in that pull are stored in a dictionary for the user to choose
from. The script then finds those locations and pulls out the weather for the
next seven days.

The point was also to test out and practice some basic Git workflow actions
such as 'fork', 'branch', and 'pull request'. Fun was had!

In the process of scraping one of NOAA's many (unappreciated) text weather
reports, I learned a good bit about Ptyhon (3, of course), and the
abovementioned libraries that I hope to more fully leverage in this script.

I spent time on some very helpful Pluralsight videos, annoyed the usual suspects
on Stack Overflow (mostly during the several hours in which I tried to master
regular expression), and probably read more of BeautifulSoup's documentation
than I really needed to for this assigmnent.
